{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "429499ad",
   "metadata": {
    "id": "e2427408-0664-46c6-8a34-aef7e8eb22ee"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import pickle\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import time\n",
    "import logging\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bee64b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a853bcbb-7a6d-4a17-bbea-8c399f75ab86",
    "outputId": "b091b6c0-f62a-4d57-e3fc-397926492466"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54cc061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(filename, name=None):\n",
    "    formatter = logging.Formatter(\n",
    "        \" %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    " \n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    " \n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    " \n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051555be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to python Action_Detetction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c2a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 子模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eb2bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ResNet模型(分析STFT频谱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8cc5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self,in_size,out_size,stride=1,downsampling=False, expansion = 4):\n",
    "        super().__init__()\n",
    "        self.expansion=expansion\n",
    "        self.downsampling=downsampling\n",
    "        self.resblock=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_size,out_channels=out_size,kernel_size=1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_size,out_channels=out_size,kernel_size=3,stride=stride, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(out_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_size,out_channels=out_size*self.expansion,kernel_size=1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_size*self.expansion)\n",
    "        )\n",
    "        if self.downsampling:\n",
    "            self.downsample=nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_size,out_channels=out_size*self.expansion,kernel_size=1,stride=stride,bias=False),\n",
    "                nn.BatchNorm2d(out_size*self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        residual=x\n",
    "        out=self.resblock(x)\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "        out+=residual\n",
    "        return self.relu(out)\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,blocks, encoder_len=1024,expansion = 4):\n",
    "        super().__init__()\n",
    "        self.expansion = expansion\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=3,kernel_size=1,stride=1,padding=0, bias=False),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=7,stride=2,padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool=nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.block1=self.get_block(64,64,blocks[0],1)\n",
    "        self.block2=self.get_block(256,128,blocks[1],2)\n",
    "        self.block3=self.get_block(512,256,blocks[2],2)\n",
    "        self.block4=self.get_block(1024,512,blocks[3],2)\n",
    "        self.fc=nn.Linear(2048,encoder_len)\n",
    "    def get_block(self,in_size,out_size,block,stride):\n",
    "        blocks=[]\n",
    "\n",
    "        blocks.append(Block(in_size,out_size,stride,downsampling=True))\n",
    "        for i in range(1,block):\n",
    "            blocks.append(Block(out_size*self.expansion,out_size))\n",
    "        return nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b=x.shape[0]\n",
    "        x=self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x=self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x=self.pool(x)\n",
    "        print(x.shape)\n",
    "        x=self.block1(x)\n",
    "        print(x.shape)\n",
    "        x=self.block2(x)\n",
    "        print(x.shape)\n",
    "        x=self.block3(x)\n",
    "        print(x.shape)\n",
    "        x=self.block4(x)\n",
    "        print(x.shape)\n",
    "        x=torch.mean(x,dim=(2,3))\n",
    "        x=x.reshape(b,-1)\n",
    "        print(x.shape)\n",
    "        return self.fc(x)\n",
    "    \n",
    "def ResNet50():\n",
    "    return ResNet([3, 4, 6, 3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet([3, 4, 23, 3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet([3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698f68c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM模型（分析MFCC）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    " \n",
    "    def __init__(self,num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm= nn.LSTM(24,64,num_layers,dropout=0.1,batch_first=True,bidirectional=True)\n",
    "        self.fc=nn.Linear(128*num_layers,256*num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output,(h,c)=self.lstm(x)\n",
    "        h=rearrange(h,'n b d -> b (n d)')\n",
    "        out=self.fc(h)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89802184",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练模型1（Triplet Loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b95e271",
   "metadata": {
    "id": "124e6f31-dc2b-4db7-8c9c-378b728038e7",
    "tags": []
   },
   "source": [
    "### 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a2c4c4",
   "metadata": {
    "id": "57472d77-fe2d-4c41-891c-1880a4fd28d6"
   },
   "outputs": [],
   "source": [
    "class Train_Data1(Dataset):\n",
    "    def __init__(self,length):\n",
    "        with open('./model_data/train_high_stft.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.labels=np.array(data['labels'])\n",
    "            self.images=data['stfts']\n",
    "            self.length=length\n",
    "        with open('./model_data/train_low.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.mfccs=data['mfccs']\n",
    "    def __getitem__(self,index):\n",
    "        anchor=np.random.choice(np.arange(0,len(self.labels)))\n",
    "        class_a=self.labels[anchor]\n",
    "        postive=np.random.choice(np.argwhere(self.labels==class_a).T[0])\n",
    "        negative=np.random.choice(np.argwhere(self.labels!=class_a).T[0])\n",
    "        return self.images[anchor],self.images[postive],self.images[negative],self.mfccs[anchor],self.mfccs[postive],self.mfccs[negative]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23c3afb0",
   "metadata": {
    "id": "8a6a2d2e-bc23-4c76-bbd3-e9a55f10c67d"
   },
   "outputs": [],
   "source": [
    "dataset_train=Train_Data1(6400)\n",
    "data_train=DataLoader(dataset_train,batch_size=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f4213c-bcd6-49ed-a877-f512a8579fd7",
   "metadata": {
    "id": "514212f2-3fff-48c7-bb7f-9ae2c4be8e16",
    "tags": []
   },
   "source": [
    "### 训练模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f481293",
   "metadata": {
    "id": "0cd8d2da-2e7e-4b40-b860-843e41057f30"
   },
   "outputs": [],
   "source": [
    "class Siamese_Train1(nn.Module):\n",
    "    def __init__(self,high,low):\n",
    "        super().__init__()\n",
    "        self.high=high\n",
    "        self.low=low\n",
    "        self.linear=nn.Linear(1536,1024)\n",
    "    def forward(self, ha,hp,hn,la,lp,ln):\n",
    "        zha=self.high(ha)\n",
    "        zhp=self.high(hp)\n",
    "        zhn=self.high(hn)\n",
    "        zla=self.low(la)\n",
    "        zlp=self.low(lp)\n",
    "        zln=self.low(ln)\n",
    "        za=self.linear(torch.cat((zha,zla),1))\n",
    "        zp=self.linear(torch.cat((zhp,zlp),1))\n",
    "        zn=self.linear(torch.cat((zhn,zln),1))\n",
    "        return za,zp,zn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261bc1b",
   "metadata": {
    "id": "dg-SP-LtMpYh",
    "tags": []
   },
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2307820",
   "metadata": {
    "id": "S77k-1uGMrwp"
   },
   "outputs": [],
   "source": [
    "def train(num_epoches,optimizer,model,loss_fn,data_train,save_itercept=5):\n",
    "    model.train()\n",
    "    logger1 = get_logger('./logger/STFT/train1_Step.log','step')\n",
    "    logger2 = get_logger('./logger/STFT/res1_Epoch.log','epoch')\n",
    "    logger3 = get_logger('./logger/STFT/tensor1_vec.log','vec')\n",
    "    for epoch in range(1,num_epoches+1):\n",
    "        loss_sum=0\n",
    "        begin=time.time()\n",
    "        logger1.info('=============Epoch:{} Strat!============='.format(epoch))\n",
    "        for i,(ha,hp,hn,la,lp,ln) in enumerate(data_train):\n",
    "            ha=ha.to(device)\n",
    "            hp=hp.to(device)\n",
    "            hn=hn.to(device)\n",
    "            la=la.to(device)\n",
    "            lp=lp.to(device)\n",
    "            ln=ln.to(device)\n",
    "            za,zp,zn=model(ha,hp,hn,la,lp,ln)\n",
    "            loss=loss_fn(za,zp,zn)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1)%50==0:logger3.info('Epoch:{}'.format(epoch)+str(za))\n",
    "            logger1.info('Epoch:{} on Step[{}/{}], Loss={:.4f}'.format(epoch ,i+1,len(data_train),float(loss)))\n",
    "            loss_sum+=float(loss)\n",
    "        end=time.time()\n",
    "        logger2.info('Epoch:{}, Loss Mean={:.4f}, Runtime={:.4f}s'.format(epoch,(float(loss_sum)/len(data_train)),(end-begin)))\n",
    "        logger1.info('=============Epoch:{} Ended!============='.format(epoch))\n",
    "        if epoch%save_itercept==0:\n",
    "            torch.save(model.high,'./model/STFT/high')\n",
    "            torch.save(model.low,'./model/STFT/low')\n",
    "            torch.save(model.linear,'./model/STFT/linear')\n",
    "            logger2.info('|| Epoch:{} Model has been saved'.format(epoch))\n",
    "        if (float(loss_sum)/len(data_train)) <0.002:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f03c294",
   "metadata": {
    "id": "79e11f3e-0b62-4644-bda3-0769c87c1de6"
   },
   "outputs": [],
   "source": [
    "high=ResNet50()\n",
    "low=LSTM(2)\n",
    "model=Siamese_Train1(high,low).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "loss_fn = nn.TripletMarginLoss(margin=1.5, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be2a41dd-52b4-4ea4-99e6-d87e1e074b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 140, 215])\n",
      "torch.Size([1, 64, 70, 108])\n",
      "torch.Size([1, 64, 35, 54])\n",
      "torch.Size([1, 256, 35, 54])\n",
      "torch.Size([1, 512, 18, 27])\n",
      "torch.Size([1, 1024, 9, 14])\n",
      "torch.Size([1, 2048, 5, 7])\n",
      "torch.Size([1, 2048])\n"
     ]
    }
   ],
   "source": [
    "for i,(ha,hp,hn,la,lp,ln) in enumerate(data_train):\n",
    "    if i==1:\n",
    "        break\n",
    "    ha=ha.to(device)\n",
    "    high(ha)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c56894",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "xswTy0SCMwKH",
    "outputId": "e5b2f17d-f943-4909-e702-73b50ecc00a5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(20,optimizer,model,loss_fn,data_train,save_itercept=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9a965",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 训练模型2(one2one分类测试)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbf5c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 生成训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0eb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Data2(Dataset):\n",
    "    def __init__(self,length):\n",
    "        with open('./model_data/train_high_stft.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.labels=np.array(data['labels'])\n",
    "            self.images=data['stfts']\n",
    "        with open('./model_data/train_low.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.mfccs=data['mfccs']\n",
    "        self.length=length\n",
    "    def __getitem__(self,index):\n",
    "        issame=np.random.choice([True,False],p=[0.3,0.7])\n",
    "        if issame:\n",
    "            cls=np.random.choice(np.arange(1,8))\n",
    "            cls_index=np.argwhere(self.labels==cls).T[0]\n",
    "            x1,x2=np.random.choice(cls_index,size=2,replace=False)\n",
    "            return self.images[x1],self.images[x2],self.mfccs[x1],self.mfccs[x2],torch.tensor(1.0)\n",
    "        else:\n",
    "            x1=np.random.choice(np.arange(0,len(self.labels)))\n",
    "            cls_index=np.argwhere(self.labels!=self.labels[x1]).T[0]\n",
    "            x2=np.random.choice(cls_index)\n",
    "            return self.images[x1],self.images[x2],self.mfccs[x1],self.mfccs[x2],torch.tensor(0.0)\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7130511",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=Train_Data2(8400)\n",
    "data_train=DataLoader(dataset_train,batch_size=70,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5b587",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_Train2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.high=torch.load('./model/STFT/high')\n",
    "        self.low=torch.load('./model/STFT/low')\n",
    "        self.linear=torch.load('./model/STFT/linear')\n",
    "        self.out=nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, h1, h2,l1,l2):\n",
    "        zh1=self.high(h1)\n",
    "        zh2=self.high(h1)\n",
    "        zl1=self.low(l1)\n",
    "        zl2=self.low(l2)\n",
    "        z1=self.linear(torch.cat((zh1,zl1),1))\n",
    "        z2=self.linear(torch.cat((zh2,zl2),1))\n",
    "        x=z1-z2\n",
    "        x=self.out(x)\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc66a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eaaca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Siamese_Train2().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39105f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epoches,optimizer,model,loss_fn,data_train,save_itercept=5):\n",
    "    model.train()\n",
    "    logger1 = get_logger('./logger/STFT/train2_Step.log','step')\n",
    "    logger2 = get_logger('./logger/STFT/res2_Epoch.log','epoch')\n",
    "    logger3 = get_logger('./logger/STFT/tensor2_vec.log','vec')\n",
    "    for epoch in range(1,num_epoches+1):\n",
    "        loss_sum=0\n",
    "        begin=time.time()\n",
    "        logger1.info('=============Epoch:{} Strat!============='.format(epoch))\n",
    "        for i,(h1, h2,l1,l2,label) in enumerate(data_train):\n",
    "            h1=h1.to(device)\n",
    "            h2=h2.to(device)\n",
    "            l1=l1.to(device)\n",
    "            l2=l2.to(device)\n",
    "            label=label.to(device)\n",
    "            res=model(h1, h2,l1,l2)\n",
    "            loss=loss_fn(res,label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1)%50==0:logger3.info('Epoch:{}'.format(epoch)+str(res))\n",
    "            logger1.info('Epoch:{} on Step[{}/{}], Loss={:.4f}'.format(epoch ,i+1,len(data_train),float(loss)))\n",
    "            loss_sum+=float(loss)\n",
    "        end=time.time()\n",
    "        logger2.info('Epoch:{}, Loss Mean={:.4f}, Runtime={:.4f}s'.format(epoch,(float(loss_sum)/len(data_train)),(end-begin)))\n",
    "        logger1.info('=============Epoch:{} Ended!============='.format(epoch))\n",
    "        if epoch%save_itercept==0:\n",
    "            torch.save(model.high,'./model/STFT/high')\n",
    "            torch.save(model.low,'./model/STFT/low')\n",
    "            torch.save(model.linear,'./model/STFT/linear')\n",
    "            torch.save(model.out,'./model/STFT/out')\n",
    "            logger2.info('|| Epoch:{} Model has been saved'.format(epoch))\n",
    "        if (float(loss_sum)/len(data_train)) <0.002:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8db6ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train(200,optimizer,model,loss_fn,data_train,save_itercept=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178e42c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 测试模型1（错误接受率测试）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fbb531",
   "metadata": {},
   "source": [
    "### 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Data1(Dataset):\n",
    "    def __init__(self,length):\n",
    "        with open('./model_data/test_high_stft.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.labels=np.array(data['labels'])\n",
    "            self.images=data['stfts']\n",
    "        with open('./model_data/test_low.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.mfccs=data['mfccs']\n",
    "        self.length=length\n",
    "    def __getitem__(self,index):\n",
    "        issame=np.random.choice([True,False],p=[0.3,0.7])\n",
    "        if issame:\n",
    "            cls=np.random.choice(np.arange(1,9))\n",
    "            cls_index=np.argwhere(self.labels==cls).T[0]\n",
    "            x1,x2=np.random.choice(cls_index,size=2,replace=False)\n",
    "            return self.images[x1],self.images[x2],self.mfccs[x1],self.mfccs[x2],torch.tensor(1)\n",
    "        else:\n",
    "            x1=np.random.choice(np.arange(0,len(self.labels)))\n",
    "            cls_index=np.argwhere(self.labels!=self.labels[x1]).T[0]\n",
    "            x2=np.random.choice(cls_index)\n",
    "            return self.images[x1],self.images[x2],self.mfccs[x1],self.mfccs[x2],torch.tensor(0)\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test=Test_Data1(length=1600)\n",
    "data_test=DataLoader(dataset_test,batch_size=48,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703c004f",
   "metadata": {},
   "source": [
    "### 测试模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_Test1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.high=torch.load('./model/STFT/high')\n",
    "        self.low=torch.load('./model/STFT/low')\n",
    "        self.linear=torch.load('./model/STFT/linear')\n",
    "        self.out=torch.load('./model/STFT/out')\n",
    "    def forward(self, h1, h2,l1,l2):\n",
    "        zh1=self.high(h1)\n",
    "        zh2=self.high(h1)\n",
    "        zl1=self.low(l1)\n",
    "        zl2=self.low(l2)\n",
    "        z1=self.linear(torch.cat((zh1,zl1),1))\n",
    "        z2=self.linear(torch.cat((zh2,zl2),1))\n",
    "        x=z1-z2\n",
    "        x=self.out(x).reshape(-1)\n",
    "        #return x\n",
    "        return (x>0.9).int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0f0a5",
   "metadata": {},
   "source": [
    "### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7000e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Siamese_Test1().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f878c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_test,epochs):\n",
    "    count=0\n",
    "    total=0\n",
    "    error_accept=0\n",
    "    accept=0\n",
    "    for epoch in range(epochs):\n",
    "        c=0\n",
    "        for i,(kh,kl,qh,ql,label) in enumerate(data_test):\n",
    "            kh=kh.to(device)\n",
    "            kl=kl.to(device)\n",
    "            qh=qh.to(device)\n",
    "            ql=ql.to(device)\n",
    "            res=model(kh,kl,qh,ql)\n",
    "            label=label.numpy()\n",
    "            #print(res.cpu().detach().numpy(),label.numpy())\n",
    "            res=res.cpu().detach().numpy()\n",
    "            accept+=np.sum((res==1))\n",
    "            e_index=np.argwhere(res!=label)\n",
    "            e_label=label[e_index]\n",
    "            error_accept+=np.sum(e_label==0)\n",
    "            res=np.sum((res==label))\n",
    "            c+=res\n",
    "        count+=c\n",
    "        total+=len(dataset_test)\n",
    "        print('Epoch {}: [{}/{}]'.format(epoch+1,c,len(dataset_test)))\n",
    "    print('Accuracy: %%%.4f, False Acceptance Rate: %%%.4f' %(count/total*100,error_accept/accept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,data_test,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d1835",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 测试模型2( one way ten shot测试)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9531594",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebeaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Data2(Dataset):\n",
    "    def __init__(self,way):\n",
    "        with open('./model_data/query.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.q_images=data['stfts']\n",
    "            self.q_mfccs=data['mfccs']\n",
    "        with open('./model_data/key.data','rb') as f:\n",
    "            data=pickle.load(f)\n",
    "            self.k_images=data['stfts']\n",
    "            self.k_mfccs=data['mfccs']\n",
    "        self.ways=way\n",
    "    def __getitem__(self,index):\n",
    "        issame=np.random.choice([True,False])\n",
    "        if issame:\n",
    "            cls=np.random.choice(np.arange(0,8))\n",
    "            q_index=np.random.choice(np.arange(0,10),self.ways,replace=False)\n",
    "            kh=self.k_images[cls]\n",
    "            kl=self.k_mfccs[cls]\n",
    "            qh=self.q_images[cls][q_index]\n",
    "            ql=self.q_mfccs[cls][q_index]\n",
    "            return kh,kl,qh,ql,torch.tensor(1)\n",
    "        else:\n",
    "            cls1,cls2=np.random.choice(np.arange(0,8),2,replace=False)\n",
    "            q_index=np.random.choice(np.arange(0,10),self.ways,replace=False)\n",
    "            kh=self.k_images[cls1]\n",
    "            kl=self.k_mfccs[cls1]\n",
    "            qh=self.q_images[cls2][q_index]\n",
    "            ql=self.q_mfccs[cls2][q_index]\n",
    "            return kh,kl,qh,ql,torch.tensor(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1600//self.ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d196bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "way=5\n",
    "dataset_test=Test_Data2(way)\n",
    "data_test=DataLoader(dataset_test,batch_size=64//way,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ea132",
   "metadata": {},
   "source": [
    "### 测试模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_Test2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.high=torch.load('./model/STFT/high')\n",
    "        self.low=torch.load('./model/STFT/low')\n",
    "        self.linear=torch.load('./model/STFT/linear')\n",
    "        self.out=torch.load('./model/STFT/out')\n",
    "    def forward(self, kh,kl,qh,ql):\n",
    "        b=kh.shape[0]\n",
    "        way=qh.shape[1]\n",
    "        qh=qh.view(-1,1,140,215)\n",
    "        ql=ql.view(-1,469,24)\n",
    "        zhk=self.high(kh)\n",
    "        zlk=self.low(kl)\n",
    "        zhq=self.high(qh)\n",
    "        zlq=self.low(ql)\n",
    "        zk=self.linear(torch.cat((zhk,zlk),1))\n",
    "        zq=self.linear(torch.cat((zhq,zlq),1))\n",
    "       \n",
    "        zq=torch.mean(zq.view(b,way,-1),dim=1)\n",
    "        x=zq-zk\n",
    "        x=self.out(x).reshape(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf62d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 开始测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c71358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Siamese_Test2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ef824-5602-46a2-9812-ac9ea2456e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,data_test,epochs,thresholds):\n",
    "    length=len(thresholds)\n",
    "    count=[0]*length\n",
    "    total=0\n",
    "    error_accept=[0]*length\n",
    "    accept=[0]*length\n",
    "    for epoch in range(epochs):\n",
    "        c=[0]*length\n",
    "        for i,(kh,kl,qh,ql,label) in enumerate(data_test):\n",
    "            label=label.numpy()\n",
    "            kh=kh.to(device)\n",
    "            kl=kl.to(device)\n",
    "            qh=qh.to(device)\n",
    "            ql=ql.to(device)\n",
    "            res=model(kh,kl,qh,ql)\n",
    "            res=res.cpu().detach()\n",
    "            for j,gate in enumerate(thresholds):\n",
    "                temp=(res>gate).int()\n",
    "                temp=temp.numpy()\n",
    "                accept[j]+=np.sum((temp==1))\n",
    "                e_index=np.argwhere(temp!=label)\n",
    "                e_label=label[e_index]\n",
    "                error_accept[j]+=np.sum(e_label==0)\n",
    "                temp=np.sum((temp==label))\n",
    "                c[j]+=temp\n",
    "                \n",
    "        total+=len(dataset_test)\n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "        for j,gate in enumerate(thresholds):\n",
    "            count[j]+=c[j]\n",
    "            #print('{} shot, Gate:{}: [{}/{}]'.format(way,gate,c[j],len(dataset_test)))\n",
    "    for j,gate in enumerate(thresholds):\n",
    "        print('%d shot, Threshold:%.2f  Accuracy: %%%.4f, False Acceptance Rate: %%%.4f' %(way,gate,count[j]/total*100,error_accept[j]/accept[j]))\n",
    "    acc=np.array(count)/total\n",
    "    far=np.array(error_accept)/np.array(accept)\n",
    "    return acc,far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e1680-d015-49d7-813b-ddde1b60fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(acc,far):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('ACC')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.plot(thresholds,acc,lw=1,c='red',marker='s',markersize=3)\n",
    "    plt.savefig('./model/STFT/'+str(way)+' shot ACC.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('False Accecpt Rate')\n",
    "    plt.ylabel('FAR')\n",
    "    plt.xlabel('Thresholds')\n",
    "    plt.plot(thresholds,far,lw=1,c='green',marker='s',markersize=3)\n",
    "    plt.savefig('./model/STFT/'+str(way)+' shot FAR.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cd595-7dba-4829-b7b6-1281822011c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds=[0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.96,0.97,0.98,0.99]\n",
    "acc,far=test(model,data_test,5,thresholds)\n",
    "plot(acc,far)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d41f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 历史子模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a664ec8",
   "metadata": {
    "id": "19fdc812-ae8d-4d59-bd26-139d46927554",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transformer模型（只包含Encoder）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Attention(nn.Module):\n",
    "    def __init__(self,dim=512,heads=8,head_dim=64):\n",
    "        super().__init__()\n",
    "        self.heads=heads\n",
    "        self.scale=head_dim**-0.5\n",
    "        self.norm=nn.LayerNorm(dim)\n",
    "        self.to_qkv=nn.Linear(dim,heads*head_dim*3,bias=False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(heads*head_dim,dim),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,input):\n",
    "        x=input\n",
    "        qkv=self.to_qkv(x).chunk(3,dim=-1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        a=F.softmax(dots,dim=-1)\n",
    "        attn_res=out = torch.einsum('bhij,bhjd->bhid', a, v)\n",
    "        attn_res=rearrange(attn_res,'b h n d -> b n (h d)')\n",
    "        x=self.to_out(x)\n",
    "        x=x+input\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f15245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fnn(nn.Module):\n",
    "    def __init__(self,dim=512,FNN_dim=2048):\n",
    "        super().__init__()\n",
    "        self.norm=nn.LayerNorm(dim)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(dim,FNN_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(FNN_dim,dim),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "    def forward(self,input):\n",
    "        x=input\n",
    "        x=self.mlp(x)\n",
    "        x=x+input\n",
    "        x=self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaed6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,dim=512,N=6,heads=8,head_dim=64,FNN_dim=2048):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(N):\n",
    "            self.blocks.append(nn.ModuleList([\n",
    "                Multi_Attention(dim,heads,head_dim),\n",
    "                Fnn(dim,FNN_dim)\n",
    "            ]))\n",
    "    def forward(self,input):\n",
    "        x=input.to(torch.float32)\n",
    "        for attention,fnn in self.blocks:\n",
    "            x=attention(x)\n",
    "            x=fnn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,input_size,seq_len,dim=512,N=6,heads=8,FNN_dim=2048,head_dim=64):\n",
    "        super().__init__()\n",
    "        self.token_embedding=nn.Linear(input_size,dim)\n",
    "        self.pos_embedding=nn.Parameter(torch.randn(1, seq_len + 1, dim))\n",
    "        self.cls_token=nn.Parameter(torch.randn(1, 1,dim))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.encoder=Encoder(dim,N,heads,head_dim,FNN_dim)\n",
    "    def forward(self,input):\n",
    "        batch_size=input.shape[0]\n",
    "        x=input.to(torch.float32)\n",
    "        x=self.token_embedding(x)\n",
    "        cls_token=self.cls_token.repeat(batch_size,1,1)\n",
    "        x=torch.cat((cls_token,x),dim=1)\n",
    "        x=x+self.pos_embedding\n",
    "        x = self.dropout(x)\n",
    "        x = self.encoder(x)\n",
    "        x=x[:,0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59499688",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### VGG模型(分析STFT频谱)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05a5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    " \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 3 * 224 * 224\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3) # 64 * 222 * 222\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=(1, 1)) # 64 * 222* 222\n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 64 * 112 * 112\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3) # 128 * 110 * 110\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=(1, 1)) # 128 * 110 * 110\n",
    "        self.maxpool2 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 128 * 56 * 56\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3) # 256 * 54 * 54\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=(1, 1)) # 256 * 54 * 54\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=(1, 1)) # 256 * 54 * 54\n",
    "        self.maxpool3 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 256 * 28 * 28\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3) # 512 * 26 * 26\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 26 * 26\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 26 * 26\n",
    "        self.maxpool4 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 512 * 14 * 14\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3) # 512 * 12 * 12\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 12 * 12\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) # 512 * 12 * 12\n",
    "        self.maxpool5 = nn.MaxPool2d((2, 2), padding=(1, 1)) # pooling 512 * 7 * 7\n",
    "        # view\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2048)\n",
    "        # softmax 1 * 1 * 1000\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # x.size(0)即为batch_size\n",
    "        in_size = x.size(0)\n",
    "\n",
    "        out = self.conv1_1(x) # 222\n",
    "        out = F.relu(out)\n",
    "        out = self.conv1_2(out) # 222\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool1(out) # 112\n",
    "\n",
    "        out = self.conv2_1(out) # 110\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2_2(out) # 110\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool2(out) # 56\n",
    "\n",
    "        out = self.conv3_1(out) # 54\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3_2(out) # 54\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3_3(out) # 54\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool3(out) # 28\n",
    "\n",
    "        out = self.conv4_1(out) # 26\n",
    "        out = F.relu(out)\n",
    "        out = self.conv4_2(out) # 26\n",
    "        out = F.relu(out)\n",
    "        out = self.conv4_3(out) # 26\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool4(out) # 14\n",
    "\n",
    "        out = self.conv5_1(out) # 12\n",
    "        out = F.relu(out)\n",
    "        out = self.conv5_2(out) # 12\n",
    "        out = F.relu(out)\n",
    "        out = self.conv5_3(out) # 12\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool5(out) # 7\n",
    "\n",
    "        # 展平\n",
    "        out = out.view(in_size, -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Action_Detetction.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "b2317070dbfd5c96636a11cd8e5baa4959ba29d1d7335a68a5494ac13aae60ee"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
