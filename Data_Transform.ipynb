{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd87adf1-b795-4387-9298-170661adfe5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import librosa.display\n",
    "import torch\n",
    "import pickle\n",
    "from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b19152-6b42-4eeb-9a31-b627fc95150a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 生成测试数据索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04b3543a-0c2d-47f0-ba8c-8503b4a1a9bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  47  62  63  99 122 131 134 137 145 147]\n"
     ]
    }
   ],
   "source": [
    "test_index=np.sort(np.random.choice(np.arange(0,150),11,replace=False))\n",
    "print(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33b94be0-8f56-49a6-8d04-612329162170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': array([ 17,  47,  62,  63,  99, 122, 131, 134, 137, 145, 147])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={}\n",
    "data['test']=test_index\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "513af47f-c1c1-4c03-a451-6273cbe263ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/index.data','wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdb625-0308-44be-8b70-91e73f909004",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc83611-9ede-4f5b-84ad-178ad6bd6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x, w):\n",
    "    # 加入高斯白噪音\n",
    "    output = x + w * np.random.normal(loc=0, scale=1, size=len(x))\n",
    "    return output.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d41ea-2322-49ce-b044-daf275b64f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(x,sr,rate):\n",
    "    return librosa.effects.time_stretch(x, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdd3e3-0226-458c-8061-061ab972a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(x):\n",
    "    return np.asfortranarray(np.flip(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624d2cd-89c9-42a7-b757-4ef283ce50d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_transform(y,sr):\n",
    "    #进行stft变换\n",
    "    nfft=int(sr*0.7)\n",
    "    data = librosa.amplitude_to_db(np.abs(librosa.stft(y,n_fft=nfft,hop_length=int(nfft/30))), ref=np.max)\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    librosa.display.specshow(data, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.show()\n",
    "    return data[12500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94da240-a0c7-4a6b-9a30-8a8564ce8c05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "actions = os.listdir('./wav/src_wav')\n",
    "for action in actions:\n",
    "    folder='./wav/src_wav/'+action+'/'\n",
    "    print(action)\n",
    "    for filename in os.listdir(folder):\n",
    "        i=int(filename[:-4])\n",
    "        y, sr = librosa.load(folder+filename, sr=None,mono=False)\n",
    "        ya1 = add_noise(x=y, w=3e-4)\n",
    "        ya2 = add_noise(x=y, w=3e-4)\n",
    "        yt1=stretch(x=y,sr=sr,rate=np.random.choice([0.6,0.7,0.8]))\n",
    "        yt2=stretch(x=y,sr=sr,rate=np.random.choice([1.2,1.3,1.4]))\n",
    "        librosa.output.write_wav(folder+str(30*1+i)+'.wav',ya1,sr)\n",
    "        librosa.output.write_wav(folder+str(30*2+i)+'.wav',ya2,sr)\n",
    "        librosa.output.write_wav(folder+str(30*3+i)+'.wav',yt1,sr)\n",
    "        librosa.output.write_wav(folder+str(30*4+i)+'.wav',yt2,sr)\n",
    "        print(folder+filename+' OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e721f0a-0a88-44cd-99a0-6ff8aa9147c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 生成高频段样本（用于Transformer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83280f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav2(path):\n",
    "    #读取wav文件\n",
    "    y, sr = librosa.load(path, sr=48000,mono=False)\n",
    "    return y,sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58919c3e-da63-412f-9a3d-94db43421dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_transform(y,sr):\n",
    "    #进行stft变换\n",
    "    nfft=int(sr*0.7)\n",
    "    data = librosa.amplitude_to_db(np.abs(librosa.stft(y,n_fft=nfft,hop_length=int(nfft/30))), ref=np.max)\n",
    "    return data[12500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cf56dc-dcb7-4343-82b4-999178f8d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/index.data','rb') as f:\n",
    "    temp=pickle.load(f)\n",
    "q=temp['query']\n",
    "k=temp['key']\n",
    "test=temp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7742c74-969e-4737-b284-5e39237b8649",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "actions = os.listdir('./model/high_wav')\n",
    "train_labels=[]\n",
    "train_stfts=[]\n",
    "test_labels=[]\n",
    "test_stfts=[]\n",
    "for action in actions:\n",
    "    folder='./wav/high_wav/'+action\n",
    "    label=int(action[6:])\n",
    "    print(label)\n",
    "    for filename in os.listdir(folder):\n",
    "        i=int(filename[:-4])\n",
    "        wavaData, framerate = read_wav2(folder+'/'+filename)\n",
    "        path='./model_data/train_high_data/'+action+'/'+filename[:len(filename)-4]+'.jpg'\n",
    "        res=stft_transform(wavaData, framerate)\n",
    "        res=torch.tensor(res)\n",
    "        if i not in test:\n",
    "            train_stfts.append(res)\n",
    "            train_labels.append(label)\n",
    "        else:\n",
    "            print(i)\n",
    "            test_stfts.append(res)\n",
    "            test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a854f-c2cc-4777-9942-68fd0ef8a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "train={}\n",
    "train['labels']=train_labels\n",
    "train['stfts']=train_stfts\n",
    "with open('./model_data/train_high.data','wb') as f:\n",
    "    pickle.dump(train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf5e79-e61c-422f-8ae6-5e36ed3f4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test={}\n",
    "test['labels']=test_labels\n",
    "test['stfts']=test_stfts\n",
    "with open('./model_data/test_high.data','wb') as f:\n",
    "    pickle.dump(test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43759be-5b78-47d2-9303-27d316515ad8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 生成高频段样本（用于CNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0336958-0a9a-400a-bbaa-45419c55dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/index.data','rb') as f:\n",
    "    temp=pickle.load(f)\n",
    "test=temp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70336b5e-1c64-4b25-9f41-2a571d02d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/test_high_img.data','rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b09d74-5658-4dbf-99ba-aa8467206c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=data['labels'][:88]\n",
    "test_images=data['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be23dadf-67e0-4d90-bce1-95256eb612b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pic(path):\n",
    "    img=Image.open(path)\n",
    "    img=img.resize((224,224))\n",
    "    img=np.array(img)\n",
    "    img=torch.tensor(img)\n",
    "    img=rearrange(img,'w h c -> c w h')\n",
    "    img=img.float()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b43d4aa-772a-4397-b77e-f199e23e9f85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "actions = os.listdir('./model_data/Doppler_pic')\n",
    "train_labels=[]\n",
    "train_images=[]\n",
    "test_labels=data['labels']\n",
    "test_images=data['images']\n",
    "for action in actions:\n",
    "    if '8' not in action:\n",
    "        continue\n",
    "    folder='./model_data/Doppler_pic/'+action\n",
    "    label=int(action[6:])\n",
    "    print(label)\n",
    "    for filename in os.listdir(folder):\n",
    "        i=int(filename[:-4])\n",
    "        path=folder+'/'+filename\n",
    "        res=get_pic(path)\n",
    "\n",
    "        test_images.append(res)\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ea3a51-f7ce-45ff-827e-c22b4b1372dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02f99fbd-1d86-459e-adfc-bbfdad839ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train={}\n",
    "train['labels']=train_labels\n",
    "train['images']=train_images\n",
    "with open('./model_data/train_high_img.data','wb') as f:\n",
    "    pickle.dump(train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da78d338-de46-477a-8a17-e0b5c014cfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.7\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test={}\n",
    "test['labels']=test_labels\n",
    "test['images']=test_images\n",
    "with open('./model_data/test_high_img.data','wb') as f:\n",
    "    pickle.dump(test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8fd9d-40b1-4b71-8651-085405dfc49f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 对于低频数据提取MFCC特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c58fdd-dab3-4b36-b733-67f9658585a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/index.data','rb') as f:\n",
    "    temp=pickle.load(f)\n",
    "q=temp['query']\n",
    "k=temp['key']\n",
    "test=temp['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81322782-ce62-42c3-8254-d07c1077f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/test_low.data','rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c115905-12f3-45a6-8647-afa37bfdc11d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "actions = os.listdir('./wav/low_wav/')\n",
    "train_labels=[]\n",
    "train_mfccs=[]\n",
    "test_labels=list(data['labels'])\n",
    "test_mfccs=data['mfccs']\n",
    "for action in actions:\n",
    "    if '8' not in action:\n",
    "        continue\n",
    "    folder='./wav/low_wav/'+action+'/'\n",
    "    label=int(action[6:])\n",
    "    print(label)\n",
    "    for filename in os.listdir(folder):\n",
    "        i=int(filename[:-4])\n",
    "        path=folder+filename\n",
    "        y, sr = librosa.load(path, sr=48000,mono=False)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=24)\n",
    "        mfcc=torch.tensor(mfcc,dtype=torch.float32)\n",
    "        mfcc=F.normalize(mfcc,dim=0)\n",
    "    \n",
    "        test_mfccs.append(mfcc)\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f961a5fe-2262-46ad-8ec1-edbce6bacb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n",
      "torch.Size([469, 24])\n"
     ]
    }
   ],
   "source": [
    "for item in test_mfccs:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e853fa2e-9692-46c9-a2ad-36e34e775cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.7\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train={}\n",
    "train['labels']=train_labels\n",
    "train['mfccs']=train_mfccs\n",
    "with open('./model_data/train_low.data','wb') as f:\n",
    "    pickle.dump(train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1af85cd8-3d90-4b42-9cf7-3fa4662b143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test={}\n",
    "test['labels']=test_labels\n",
    "test['mfccs']=test_mfccs\n",
    "with open('./model_data/test_low.data','wb') as f:\n",
    "    pickle.dump(test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbebca9-386c-4e4b-a1ab-37303b47c034",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 生成query和key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1986d8f-75d7-4da1-8042-46d0a357bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model_data/test_high_img.data','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "    labels=np.array(data['labels'])\n",
    "    images=data['images']\n",
    "with open('./model_data/test_low.data','rb') as f:\n",
    "    data=pickle.load(f)\n",
    "    labels=np.array(data['labels'])\n",
    "    mfccs=data['mfccs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001d48e-1dff-4aab-9886-c76434df27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_images=[]\n",
    "query_mfccs=[]\n",
    "key_images=[]\n",
    "key_mfccs=[]\n",
    "for cls in range(1,9):\n",
    "    index=np.argwhere(labels==cls).T[0]\n",
    "    q_index=np.random.choice(index,10,replace=False)\n",
    "    q_index.sort()\n",
    "    key=np.setdiff1d(index, q_index)[0]\n",
    "    key_images.append(images[key].numpy())\n",
    "    key_mfccs.append(mfccs[key].numpy())\n",
    "    print(key)\n",
    "    print(q_index)\n",
    "    for i in q_index:\n",
    "        query_images.append(images[i].numpy())\n",
    "        query_mfccs.append(mfccs[i].numpy())\n",
    "query_images=np.array(query_images).reshape(8,10,3,224,224)\n",
    "query_mfccs=np.array(query_mfccs).reshape(8,10,469,24)\n",
    "key_images=np.array(key_images)\n",
    "key_mfccs=np.array(key_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7858bf2a-072d-4c6b-b4ad-f6192e18b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_images=torch.from_numpy(query_images)\n",
    "query_mfccs=torch.from_numpy(query_mfccs)\n",
    "key_images=torch.from_numpy(key_images)\n",
    "key_mfccs=torch.from_numpy(key_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3547e35c-1a22-43c8-b193-5bbc90189e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 10, 3, 224, 224])\n",
      "torch.Size([7, 10, 469, 24])\n",
      "torch.Size([7, 3, 224, 224])\n",
      "torch.Size([7, 469, 24])\n"
     ]
    }
   ],
   "source": [
    "print(query_images.shape)\n",
    "print(query_mfccs.shape)\n",
    "print(key_images.shape)\n",
    "print(key_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27a6f2cc-2660-467c-9c09-e39b1ecfff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={}\n",
    "key={}\n",
    "query['images']=query_images\n",
    "query['mfccs']=query_mfccs\n",
    "key['images']=key_images\n",
    "key['mfccs']=key_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02ed94e9-5aec-4f89-b3a1-41ca9f884216",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./model_data/key.data','wb') as f:\n",
    "    pickle.dump(key,f)\n",
    "with open('./model_data/query.data','wb') as f:\n",
    "    pickle.dump(query,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
